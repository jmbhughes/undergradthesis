\documentclass[11pt]{article}
\usepackage{times,graphicx,epstopdf,fancyhdr,amsfonts,amsthm,amsmath,url,xspace}
\usepackage[left=0.5in,top=1in,right=0.5in,bottom=1in]{geometry}
\usepackage{indentfirst}
\pagestyle{fancy}
\usepackage[compact]{titlesec}

% Comment out for single spacing
%\baselineskip 20pt


\lhead{Thesis Proposal}
\chead{Computer Science}
\rhead{Marcus Hughes}
\lfoot{\today}
\rfoot{Williams College}
\cfoot{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\headwidth}{\textwidth}
\renewcommand{\footrulewidth}{0.4pt}


\begin{document}

\section{Motivation}
Space weather has dangerous and expensive consequences including  harm to astronauts and satellites, destruction of power grids, and routine rerouting of polar flights. Coronal mass ejections, one danger resulting when the Sun spews releases large amounts of charged material sometimes towards Earth, have been recorded to reach speeds of up to 2000 miles per hour, reaching Earth within the day. It is critical to have early warning of such events to enact proper protections. The new Solar Ultraviolet Imager, a camera aboard the National Oceanic and Atmospheric Administration's (NOAA) GOES-R weather satellite, responds to this need as it captures an image of the Sun every 10 seconds. This flood of data cannot be digested by human forecasters quick enough, necessitating machine learning image classification to identify important events. Machine learning also allows for organized archival of the projected 20 years of imaging, allowing researchers to find relevant data to test new solar models. This is an interesting supervised machine learning problem because it operates on movies of multi-spectral, noisy images. 

\section{Completed Work and Issues}
I began this project as an REU student during the summer of 2017 at NOAA in Boulder, Colorado. During that time, I developed a naive Bayesian classifier (similar to \cite{rigler2012}) and a feed-forward neural network classifier. I created a utility allowing me to create labeled images of the Sun for training the classifiers. (With the addition of new data, part of my project is to redesign this tool.) The classifiers were very successful and greatly exceeded the NOAA's existing implementation approach's performance in qualitative comparison. Requiring only seconds on a 2015 Macbook pro, they clearly were faster than humans and could be deployed for real-time use.  However, both models were unable to reliably discern between filaments and coronal holes, the latter resulting in dangerous high speed solar winds. To remedy this, I am working to incorporate H-alpha imagery which distinguishes the two classes. Both approaches only considered the spectral qualities on a pixel by pixel basis and ignored the images' spatial and temporal structure when classifying. This is a severe limitation that I would like to spend the majority of my time developing. 

This summer's work was a proof of concept and a first step toward a system that can run on input images in a nonstop fashion. During the past months of my independent study, I have worked on a more rigorous and unbiased training approach involving a better labeling utility and multiple human trainers. I plan to complete this as part of my thesis project. Inspired by Earth remote sensing papers, I developed a random forest classifier that rivals the performance of my feed forward neural network. I have been reading background papers to develop an intimate understanding of the state-of-the-art computer vision and solar physics. 

\section{Project Plan}
The research on identifying coronal dimmings, sources of coronal mass ejections, and sigmoids (thought to be precursors to dangerous flares) in an automated fashion is limited \cite{cheng2016, robbrecht2009}. Existing systems often use complicated rules instead of a general machine learning model. I plan to continue advancing the performance of my classifiers. To do this, I will first collaborate with researchers at NOAA to establish an unbiased an representative training set of solar phenomena. With this training, I will run it through my existing classifiers to establish a quanitative meaasurement of performance. I also will work to incorporate spatial and temporal context into the classifiers, most notably by developing a convolutional neural network approach to the problem. This has only been attempted once \cite{kucuk2017} and was not used to create maps but label small sections of images. Cutting edge computer vision \cite{he2017} could improve performance and classification flexibility greatly, even allowing the classifier to move beyond image by image labeling and consider the feature evolving through time. 

{\footnotesize
\bibliographystyle{abbrv}
\begin{thebibliography}{}
\bibitem{cheng2016} J.X. Cheng and J. Qiu, 2016, The Astrophysical Journal, 825, 1,
\bibitem{he2017} K. He, G. Gkioxari, P. Dollar, and R. Girschick,  2017, presented at IEEE Internaional Conference on Computer Vision, arXiv:1703.06870v2
\bibitem{kucuk2017} A. Kucuk, J. M. Banda, and R. A. Angryk, 2017, ISAISC, PArt I, LNAI 10245, pp. 118-130
\bibitem{rigler2012} E. J. Rigler, S. M. Hill, A. A. Reinard, and R. A. Steenburg, 2012, Space Weather, 10, 8
\bibitem{robbrecht2009} E. Robbrecht, D. Berghmans, and R. A. M. Van der Linden, 2009, The Astrophysical Journal, 691, 2
\end{thebibliography}
}
\end{document}